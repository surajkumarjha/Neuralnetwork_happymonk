{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset =pd.read_csv('/Users/surajkumarjha/Downloads/data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing is being carried out here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing M with 1 and B with 0....\n",
    "dataset['diagnosis'] = dataset['diagnosis'].apply(lambda x : 1 if x=='M' else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the unwanted features from the dataset...\n",
    "\n",
    "final_dataset=dataset.drop('id',axis=1)\n",
    "final_dataset = final_dataset.drop('Unnamed: 32', axis=1)\n",
    "final_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking NA values\n",
    "final_dataset.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of  dependent and independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: 'Dependent variable' whreas x:'Independent variable'\n",
    "y = final_dataset.diagnosis\n",
    "x = final_dataset.iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting ( splitting data into train and test split  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the test size as 15 % of dataset \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state= 101, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sequential model from Keras\n",
    "model = Sequential()\n",
    "# Adding input layer with 30 neurons with 30 input dimensions i.e equal to number of x features\n",
    "model.add(Dense(30, input_dim=30, activation='relu'))\n",
    "# Adding hidden layer with 15 neurons \n",
    "model.add(Dense(15, activation='relu'))\n",
    "# Adding output layer with 1 neuron\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here our prediction column has two categories M and B so it is binary classification problem and for binary classification problem sigmoid is best activation function. It returns either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',f1_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are many optimizers, loss functions and matrices but, i am using binary_crossentropy beacuse it is a binary classification problem and accuracy as a matrix due to classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 483 samples\n",
      "Epoch 1/36\n",
      "483/483 [==============================] - 0s 222us/sample - loss: 0.2450 - acc: 0.9130 - f1_score: 0.8605\n",
      "Epoch 2/36\n",
      "483/483 [==============================] - 0s 163us/sample - loss: 0.2217 - acc: 0.9193 - f1_score: 0.9004\n",
      "Epoch 3/36\n",
      "483/483 [==============================] - 0s 182us/sample - loss: 0.2247 - acc: 0.9151 - f1_score: 0.8816\n",
      "Epoch 4/36\n",
      "483/483 [==============================] - 0s 197us/sample - loss: 0.2062 - acc: 0.9296 - f1_score: 0.9063\n",
      "Epoch 5/36\n",
      "483/483 [==============================] - 0s 187us/sample - loss: 0.2397 - acc: 0.9172 - f1_score: 0.8800\n",
      "Epoch 6/36\n",
      "483/483 [==============================] - 0s 179us/sample - loss: 0.2052 - acc: 0.9193 - f1_score: 0.8795\n",
      "Epoch 7/36\n",
      "483/483 [==============================] - 0s 159us/sample - loss: 0.2243 - acc: 0.9193 - f1_score: 0.8885\n",
      "Epoch 8/36\n",
      "483/483 [==============================] - 0s 161us/sample - loss: 0.1979 - acc: 0.9255 - f1_score: 0.9033\n",
      "Epoch 9/36\n",
      "483/483 [==============================] - 0s 160us/sample - loss: 0.2081 - acc: 0.9296 - f1_score: 0.9023\n",
      "Epoch 10/36\n",
      "483/483 [==============================] - 0s 174us/sample - loss: 0.1915 - acc: 0.9255 - f1_score: nan\n",
      "Epoch 11/36\n",
      "483/483 [==============================] - 0s 212us/sample - loss: 0.1901 - acc: 0.9358 - f1_score: 0.9144\n",
      "Epoch 12/36\n",
      "483/483 [==============================] - 0s 237us/sample - loss: 0.2129 - acc: 0.9255 - f1_score: 0.9006\n",
      "Epoch 13/36\n",
      "483/483 [==============================] - 0s 176us/sample - loss: 0.2044 - acc: 0.9255 - f1_score: nan\n",
      "Epoch 14/36\n",
      "483/483 [==============================] - 0s 194us/sample - loss: 0.1848 - acc: 0.9379 - f1_score: 0.9172\n",
      "Epoch 15/36\n",
      "483/483 [==============================] - 0s 387us/sample - loss: 0.1783 - acc: 0.9317 - f1_score: nan\n",
      "Epoch 16/36\n",
      "483/483 [==============================] - 0s 191us/sample - loss: 0.2246 - acc: 0.9234 - f1_score: 0.8891\n",
      "Epoch 17/36\n",
      "483/483 [==============================] - 0s 161us/sample - loss: 0.1958 - acc: 0.9337 - f1_score: 0.8929\n",
      "Epoch 18/36\n",
      "483/483 [==============================] - 0s 224us/sample - loss: 0.2184 - acc: 0.9358 - f1_score: nan\n",
      "Epoch 19/36\n",
      "483/483 [==============================] - 0s 176us/sample - loss: 0.2514 - acc: 0.9110 - f1_score: nan\n",
      "Epoch 20/36\n",
      "483/483 [==============================] - 0s 210us/sample - loss: 0.1840 - acc: 0.9317 - f1_score: 0.9083\n",
      "Epoch 21/36\n",
      "483/483 [==============================] - 0s 172us/sample - loss: 0.1759 - acc: 0.9317 - f1_score: nan\n",
      "Epoch 22/36\n",
      "483/483 [==============================] - 0s 246us/sample - loss: 0.1779 - acc: 0.9420 - f1_score: 0.9218\n",
      "Epoch 23/36\n",
      "483/483 [==============================] - 0s 182us/sample - loss: 0.1872 - acc: 0.9337 - f1_score: 0.9037\n",
      "Epoch 24/36\n",
      "483/483 [==============================] - 0s 484us/sample - loss: 0.1704 - acc: 0.9317 - f1_score: nan\n",
      "Epoch 25/36\n",
      "483/483 [==============================] - 0s 204us/sample - loss: 0.2252 - acc: 0.9275 - f1_score: nan\n",
      "Epoch 26/36\n",
      "483/483 [==============================] - 0s 214us/sample - loss: 0.1770 - acc: 0.9358 - f1_score: 0.9147\n",
      "Epoch 27/36\n",
      "483/483 [==============================] - 0s 198us/sample - loss: 0.1914 - acc: 0.9358 - f1_score: 0.9109\n",
      "Epoch 28/36\n",
      "483/483 [==============================] - 0s 212us/sample - loss: 0.2289 - acc: 0.9255 - f1_score: nan\n",
      "Epoch 29/36\n",
      "483/483 [==============================] - 0s 179us/sample - loss: 0.1798 - acc: 0.9317 - f1_score: 0.9133\n",
      "Epoch 30/36\n",
      "483/483 [==============================] - 0s 194us/sample - loss: 0.1811 - acc: 0.9275 - f1_score: nan\n",
      "Epoch 31/36\n",
      "483/483 [==============================] - 0s 499us/sample - loss: 0.1725 - acc: 0.9275 - f1_score: 0.9007\n",
      "Epoch 32/36\n",
      "483/483 [==============================] - 0s 162us/sample - loss: 0.1594 - acc: 0.9420 - f1_score: 0.9224\n",
      "Epoch 33/36\n",
      "483/483 [==============================] - 0s 223us/sample - loss: 0.1695 - acc: 0.9420 - f1_score: 0.9193\n",
      "Epoch 34/36\n",
      "483/483 [==============================] - 0s 209us/sample - loss: 0.2050 - acc: 0.9275 - f1_score: nan\n",
      "Epoch 35/36\n",
      "483/483 [==============================] - 0s 509us/sample - loss: 0.1853 - acc: 0.9296 - f1_score: nan\n",
      "Epoch 36/36\n",
      "483/483 [==============================] - 0s 220us/sample - loss: 0.1729 - acc: 0.9337 - f1_score: 0.9140\n"
     ]
    }
   ],
   "source": [
    "# Training the model with epocs = 40\n",
    "history = model.fit(x_train, y_train, epochs=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model \n",
    "p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating unseen data array to predict\n",
    "new = [[12.013, 0.32, 43.78, 0.124, 54.97, 0.23, 3.75, 64.35, 12.642, 0.032, 87.232, 32.76, 65.97, 23.087, 45.23, 89.02, 99.54, 45.34, 0.23, 0.54, 53.53, 12.65, 76.76, 121.09, 43.001, 12.54, 64.34, 19.076, 143.02, 75.01, ]]\n",
    "len(new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the result for given unseen data.\n",
    "result = model.predict(np.array(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 0.0:\n",
    "    print(\"B\")\n",
    "else:\n",
    "    print(\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 1s 2ms/sample - loss: 0.2446 - acc: 0.9172 - f1_score: 0.9037\n",
      "0.9171843 0.24458344553753456 0.9036682\n"
     ]
    }
   ],
   "source": [
    "# Checking for train accuracy\n",
    "train_loss,train_accuracy,train_f1score = model.evaluate(x_train,y_train)\n",
    "print(train_accuracy, train_loss, train_f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 153us/sample - loss: 0.2810 - acc: 0.8953 - f1_score: 0.8777\n",
      "0.89534885 0.28102324244587923 0.877732\n"
     ]
    }
   ],
   "source": [
    "# Checking for test accuracy\n",
    "test_loss,test_accuracy, test_f1score = model.evaluate(x_test,y_test)\n",
    "print(test_accuracy, test_loss, test_f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021835446\n"
     ]
    }
   ],
   "source": [
    "# Difference between train and test accuracy\n",
    "accuracy_difference = train_accuracy - test_accuracy\n",
    "print(accuracy_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss vs epocs graph\n",
    "loss_values = history.history['loss']\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036439796908344674"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(train_loss-test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
